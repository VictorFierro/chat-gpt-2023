# Clase 103 - Introducción a la librería OpenAI para Python

> **Centro de Investigación en Computación**
>
> *Instituto Politécnico Nacional*
>
> Departamento de Diplomados y Extensión Profesional
>

![CIC-IPN](https://www.cic.ipn.mx/images/logos/logositiocicletras.png)

**Profesor**: [Alan Badillo Salas](alan@nomadacode.com)

---

## Contenido

    1. Modelos y análisis de textos
        - Modelos de texto
        - Expresiones regulares
        - Extracción del vocabulario
        - Vectorización de palabras
        - Conteos y frecuencias
        - Probabilidad de ocurrencias
        - N-Gramas
    2. Introducción a la librería OpenAI para Python
        - Instalación y configuración de la librería
        - Usar Chat Completion 

## Objetivos

Aprender a realizar instrucciones desde Python hacia CHATGPT. Cargar las instrucciones desde archivos de texto y archivos CSV. Establecer un flujo de trabajo automatizado para la resolución de tareas cargadas desde archivos de texto/CSV y dirigidas hacia archivos de texto/CSV.

## Introducción

CHATGPT es una herramienta que nos permite procesar y analizar de manera inteligente textos, además de la posibilidad de utilizarlo como un asistente de programación.

Podemos ver a CHATGPT en dos aplicaciones directas:

1. Como un asistente que nos recupera información compleja de un texto, por ejemplo, darle un texto y solicitarle un resumen, las palabras claves, los personajes involucrados, las situaciones identificadas, si hablan bien o mal de un personaje, si se menciona una institución, los precios y fechas mencionadas, números de teléfonos, correos y cuentas bancarias mecionadas, entre un sin fin más. Esto supera incluso a un buen asistente humano.
2. Como un asistente que genere el código necesario para resolver una tarea, por ejemplo, un código en Python que abra un archivo CSV, extraíga los datos de las columnas SALARIO y NIVEL_EDUCATIVO y cree una gráfica de correlación entre ambas, y finalmente escriba ambas columnas en un archivo CSV. Esto también supera por mucho a un humano estándar en cuánto a tiempo de respuesta. Mientras un programador podría perder tiempo investigando cómo resolver el problema, en cuestión de segundos CHATGPT nos daría los códigos.

Con esto en mente, usaremos a CHATGPT como nuestro asistente personal para hacer **Análisis de Textos** en una forma avanzada.

## Modelos y análisis de textos

Los análisis clásicos sobre los textos consisten identificar las palabras de mayor frecuencia, extraer patrones regulares, vectorizar las palabras, hacer conteos y frecuencia de palabras y analizar los n-gramas.

Con esto en mente vamos a diseñar una serie funciones para Python, que automaticen nuestro flujo de análisis de textos.

### Modelos de texto

Un modelo de texto implica entender la estructura básica del texto, por ejemplo, si se trata de una noticia, podremos ubicar un título, fecha, autor y el contenido de la noticia. Dentro de ese modelo podríamos determinar patrones de búsqueda para reconocer los datos dentro del texto.

Algunos modelos clásicos son:

- **Textos que mencionan fechas** - Ejemplo: `2023-03-12`, `12/03/2023`, `marzo 12, 2023`, `12 de marzo del 2023`, `march 12th, 2023`, `el 12 de marzo del año actual`, `el día 12, del mes de marzo del 2023`, `hace dos días (suponiendo que hoy es 14 de marzo del 2023)`, `antier (suponiendo que hoy es 14 de marzo del 2023)`.
- **Textos que mencionan precios** - Ejemplo: `$1,234.56`, `mil docientos treinta y cuatro con 56 centavos`, `con un precio de dos millones con 76 pesos`.
- **Textos que mencionan teléfonos, correos, cuentas y más** - Ejemplo: `ana.ming@gmail.com`, `@dragonnomada`, `https://www.ballena.app`, `+52 1 551 234 5678`, `llamale al 55238890 con la extensión 24`, `la cuenta es 5212349988833322`, `mándale un correo a pepe123 arroba gmail punto com`, `el número de referencia es 445633`.
- **Textos que mencionan personas, instituciones, paises y más** - `dile a Ana Ming que me pague`, `La UNESCO aceptó que la tierra es patrimonio de la humanidad`, `En dos días X será la nueva red social y dejará de ser Twitter`, `alguien sabe como se escribe feisbuq?`, `vamos a Japón a comernos una hamburguesa a ver si se parece a la original`.

Podemos observar que dentro de los modelos de texto, algunos son más regulares que otros, por ejemplo, si quisieramos reconocer una fecha, sería más fácil reconocer `12/03/2023` que `antier`. Esta última requeriría mucha inteligencia para determinar que esa palabra es una fecha.

### Expresiones regulares

Las expresiones regulares son conjuntos de MARCADORES que nos permiten reconocer dentro de un texto patrones reguales, por ejemplo:

* `[A-Z]+` - Reconoce dentro de un texto uno o más caracteres consecutivos entre la `A` y la `Z`, por ejemplo, dentro del texto: `La UNESCO aceptó que la TIERRA es patrimonio de la humanidad`, sería capaz de reconocer: `L`, `UNESCO` y `TIERRA`, ya que estas cumplen el patrón regular.
* `[a-z\.\-\_]+@[a-z]+\.com` - Reconoce dentro de un texto caracteres en minúscula de la `a` a la `z`, signos de `.`, `-` y `_` antes de una arroba (`@`), seguido de más de un caracter entre `a` y `z`, previos a un `.com`, por ejemplo, sería capaz de reconocer dentro del texto: `Los correos son: pepe@gmail.com, dany_23@hotmail.com, pedro-99@el-diario.com y paty.123@example.gob`, solo los siguientes correos: `pepe@gmail.com` y `dany_23@hotmail.com`. Porque `el-diario` no se apega al patrón regular y `.gob` tampoco.

Extraer datos usando expresiones regulares es bastante limitado en un análisis real, ya que sólo podríamos reconocer patrones reguales como `12/03/23` o `15/08/2024` mediante el patrón `\d{2}\/\d{2}\/\d{2}`, sin embargo, reconocer `el día dos de abril del 2023`, sería bastante complejo lograrlo.

CHATGPT adquiere una ventaja en análisis de patrones regulares y para demostrarlo hagamos las siguientes solicitudes:

```text

SOLICITUDES A CHATGPT:

=== .1

Del siguiente texto:

- **Textos que mencionan fechas** - Ejemplo: `1963-08-01`, `24/02/1966`, `agosto 21, 2023`, `22 de julio de 1987`, `feb 14th, 1994`, `el 7 de octubre del 98`, `el día 12, del mes de agosto del 2023`, `hace dos días (suponiendo que hoy es 15 de marzo de 1990)`, `antier (suponiendo que hoy es 1 de julio del 2021)`.

Recupera todas las fechas en forma de lista en el formato ISO

--- RESPUESTA ---

Aquí tienes la lista de fechas recuperadas del texto en formato ISO:

- `1963-08-01`
- `1966-02-24`
- `2023-08-21`
- `1987-07-22`
- `1994-02-14`
- `1998-10-07`
- `2023-08-12`
- `1990-03-13` (hace dos días a partir del 15 de marzo de 1990)
- `2021-06-29` (antier a partir del 1 de julio de 2021)

Ten en cuenta que en el último caso ("antier") hubo una discrepancia entre la fecha que proporcionaste (1 de julio del 2021) y el resultado que obtuviste (antier a partir del 1 de julio de 2021). El resultado proporcionado es coherente con la fecha que diste.

=== .2

Dame la lista de los días de la semana para cada fecha de la lista anterior

--- RESPUESTA ---

Aquí tienes la lista de los días de la semana correspondientes a cada fecha de la lista anterior:

- `1963-08-01`: Martes
- `1966-02-24`: Jueves
- `2023-08-21`: Lunes
- `1987-07-22`: Miércoles
- `1994-02-14`: Lunes
- `1998-10-07`: Miércoles
- `2023-08-12`: Sábado
- `1990-03-13`: Martes (hace dos días a partir del 15 de marzo de 1990)
- `2021-06-29`: Martes (antier a partir del 1 de julio de 2021)

Si necesitas más información o ayuda, no dudes en preguntar.

=== .3

Dame la lista de precios en formato $X,XXX.YY del texto siguiente:

- **Textos que mencionan precios** - Ejemplo: `$1,234.56`, `mil docientos treinta y cuatro con 56 centavos`, `con un precio de dos millones con 76 pesos`.

--- RESPUESTA ---

Lamento informarte que mi capacidad para interpretar y convertir números en palabras es limitada, y no tengo la capacidad de realizar conversiones complejas entre números escritos en palabras y formatos numéricos. Sin embargo, puedo ayudarte con otras consultas o tareas. Si tienes alguna otra pregunta o solicitud, no dudes en decírmelo.

=== .4

Dame la lista de números que seas capaces de reconocer del siguiente texto:

- **Textos que mencionan precios** - Ejemplo: `$1,234.56`, `mil docientos treinta y cuatro con 56 centavos`, `con un precio de dos millones con 76 pesos`.

--- RESPUESTA ---

Entiendo. Aquí tienes la lista de números que puedo reconocer del texto:

- `$1,234.56`
- `mil docientos treinta y cuatro con 56 centavos`
- `dos millones con 76 pesos`

Si tienes alguna otra pregunta o necesitas más ayuda, no dudes en preguntar.

=== .5

Puedes convertir la lista anterior en números?

--- RESPUESTA ---

Claro, puedo ayudarte a convertir la lista de números en formatos legibles. Aquí tienes la conversión de los números:

- `$1,234.56`: 1234.56
- `mil docientos treinta y cuatro con 56 centavos`: 1230.56
- `dos millones con 76 pesos`: 2000076.00

Si tienes más preguntas o necesitas más ayuda, no dudes en preguntar.

```

> **EJERCICIO:** Diseña un modelo de texto que involucre personajes, fechas, lugares, productos, precios, cuentas o números de teléfonos y establece una serie de preguntas para recuperar la información del texto, por ejemplo, ¿Qué personas están involucradas en el texto?

### Extracción del vocabulario

Para un texto de tamaño medio (100 palabras o más), recupera las palabras distintas y pide a CHATGPT que te diga la relevancia de cada palabra. 

### Vectorización de palabras

Para un texto de tamaño medio (100 palabras o más), pide la lista númerada de todas las palabras distintas ordenadas alfabeticamente. 

### Conteos y frecuencias

Para un texto de tamaño medio (100 palabras o más), recupera el conteo o repetición de cada palabra y la frecuencia con la que se repite respecto a otras.

### Probabilidad de ocurrencias

Para un texto de tamaño medio (100 palabras o más), recupera la probabilidad de que cada palabra ocurra.

### N-Gramas

Para un texto de tamaño medio (100 palabras o más), recupera los n-gramas, es decir, las palabras consecutivas de **n-en-n**, por ejemplo, los n-gramas de 4 en 4 (debería mostrar conjuntos consecutivos de 4 en 4 palabras que vayan ocurriendo sobre el texto).

## Introducción a la librería OpenAI para Python

Podemos hacer consultas a CHAGPT directamente desde Python usando la librería de **OpenAI** para Python.

### Instalación y configuración de la librería

Para hacer consultas a ChatGPT utilizando la librería de OpenAI en Google Colab, puedes seguir los siguientes pasos:

1. Instala la librería de OpenAI si aún no lo has hecho. Puedes hacerlo ejecutando el siguiente comando en una celda de código en Google Colab:

```python
!pip install openai
```

2. Importa la librería y configura tu clave de API. Necesitarás tu clave de API de OpenAI para autenticarte. Puedes obtenerla desde tu cuenta en la plataforma de OpenAI.

> 

```python
import openai

openai.api_key = "TU_CLAVE_DE_API"
```

3. Realiza una consulta a ChatGPT. Puedes usar la función `openai.Completion.create()` para generar una respuesta del modelo. Aquí tienes un ejemplo:

> [https://platform.openai.com/account/rate-limits](https://platform.openai.com/account/rate-limits)

```python
response = openai.Completion.create(
    engine="davinci-codex",  # Puedes usar "text-davinci-003" si prefieres GPT-3
    prompt="Dime algo interesante sobre la historia de la humanidad.",
    max_tokens=50  # Puedes ajustar este valor según la longitud deseada de la respuesta
)

print(response.choices[0].text.strip())
```

Recuerda reemplazar `"TU_CLAVE_DE_API"` con tu clave de API real.

4. Ejecuta la celda para obtener la respuesta generada por el modelo.

Es importante tener en cuenta que la librería de OpenAI y los detalles de su uso pueden cambiar con el tiempo. Asegúrate de consultar la documentación oficial de OpenAI para obtener la información más actualizada sobre cómo interactuar con sus modelos utilizando Python.

Ten en cuenta también que el modelo "davinci-codex" es especialmente bueno para tareas de programación y generación de texto basado en código. Si prefieres utilizar GPT-3 para tareas más generales, puedes reemplazar "davinci-codex" con "text-davinci-003".

### Usar Chat Completion

Las cuotas para usar CHATGPT desde el API están bastante limitadas. Yo pagué la subscripción de CHATGPT-4 PLUS pero es solo en chat, para las llamadas en API no cubre la tarifa de $20 dólares, por lo que no conviene pagarlo ya que el modelo también está entrenado hasta septiembre del 2021, no hay mejoras notables entre la versión 3.5 desafortunadamente.

Para usar el API con pago debes ingresar a [https://platform.openai.com/account](https://platform.openai.com/account) la cual también se pagó 🥲 y generó un costo de $5 dólares por la activación (no sé si reembolsables 🥲🥲). Esto requiere configurar el método de pago. Cada consulta generará algunos centavos de uso. Aunque se pueden generar claves del API sin hacer ningún pago.

Realizaremos el siguiente ejercicio para probar la funcionalidad de CHATGPT con Python.

Todos los códigos están probados en Google Colab.

![Uso de CHATGPT via API](./screenshots/c103/image.png)

En la siguiente lista se muestran los modelos disponibles y sus límites:

| MODEL                                      | TPM          | RPM   |
|--------------------------------------------|--------------|-------|
| **CHAT**                                   |              |       |
| gpt-3.5-turbo                              | 90,000       | 3,500 |
| gpt-3.5-turbo-0301                         | 90,000       | 3,500 |
| gpt-3.5-turbo-0613                         | 90,000       | 3,500 |
| gpt-3.5-turbo-16k                          | 180,000      | 3,500 |
| gpt-3.5-turbo-16k-0613                     | 180,000      | 3,500 |
| **TEXT**                                   |              |       |
| ada                                        | 250,000      | 3,000 |
| ada-code-search-code                       | 250,000      | 3,000 |
| ada-code-search-text                       | 250,000      | 3,000 |
| ada-search-document                        | 250,000      | 3,000 |
| ada-search-query                           | 250,000      | 3,000 |
| ada-similarity                             | 250,000      | 3,000 |
| babbage                                    | 250,000      | 3,000 |
| babbage-code-search-code                   | 250,000      | 3,000 |
| babbage-code-search-text                   | 250,000      | 3,000 |
| babbage-search-document                    | 250,000      | 3,000 |
| babbage-search-query                       | 250,000      | 3,000 |
| babbage-similarity                         | 250,000      | 3,000 |
| code-davinci-edit-001                      | 150,000      | 20    |
| code-search-ada-code-001                   | 250,000      | 3,000 |
| code-search-ada-text-001                   | 250,000      | 3,000 |
| code-search-babbage-code-001               | 250,000      | 3,000 |
| code-search-babbage-text-001               | 250,000      | 3,000 |
| curie                                      | 250,000      | 3,000 |
| curie-instruct-beta                        | 250,000      | 3,000 |
| curie-search-document                      | 250,000      | 3,000 |
| curie-search-query                         | 250,000      | 3,000 |
| curie-similarity                           | 250,000      | 3,000 |
| davinci                                    | 250,000      | 3,000 |
| davinci-instruct-beta                      | 250,000      | 3,000 |
| davinci-search-document                    | 250,000      | 3,000 |
| davinci-search-query                       | 250,000      | 3,000 |
| davinci-similarity                         | 250,000      | 3,000 |
| text-ada-001                               | 250,000      | 3,000 |
| text-babbage-001                           | 250,000      | 3,000 |
| text-curie-001                             | 250,000      | 3,000 |
| text-davinci-001                           | 250,000      | 3,000 |
| text-davinci-002                           | 250,000      | 3,000 |
| text-davinci-003                           | 250,000      | 3,000 |
| text-davinci-edit-001                      | 150,000      | 20    |
| text-embedding-ada-002                     | 1,000,000    | 3,000 |
| text-search-ada-doc-001                    | 250,000      | 3,000 |
| text-search-ada-query-001                  | 250,000      | 3,000 |
| text-search-babbage-doc-001                | 250,000      | 3,000 |
| text-search-babbage-query-001              | 250,000      | 3,000 |
| text-search-curie-doc-001                  | 250,000      | 3,000 |
| text-search-curie-query-001                | 250,000      | 3,000 |
| text-search-davinci-doc-001                | 250,000      | 3,000 |
| text-search-davinci-query-001              | 250,000      | 3,000 |
| text-similarity-ada-001                    | 250,000      | 3,000 |
| text-similarity-babbage-001                | 250,000      | 3,000 |
| text-similarity-curie-001                  | 250,000      | 3,000 |
| text-similarity-davinci-001                | 250,000      | 3,000 |
| **MODERATION**                             |              |       |
| text-moderation-latest                     | 150,000      | 1,000 |
| text-moderation-stable                     | 150,000      | 1,000 |
| **IMAGE**                                  |              |       |
| DALL·E 2                                   | 50 IMG/MIN   | ∞     |
| **AUDIO**                                  |              |       |
| whisper-1                                  | 25,000,000   | 50    |
| **OTHER**                                  |              |       |
| Default limits for all other models        | 250,000      | 3,000 |

La columna "TPM" en la tabla que proporcionaste se refiere a "Tokens Per Minute". Un "token" en el contexto de modelos de lenguaje como los de OpenAI puede ser tan corto como un carácter o tan largo como una palabra. Por ejemplo, la frase "ChatGPT es genial" se divide en cinco tokens: ["Chat", "G", "PT", " es", " genial"].

Los límites de tokens por minuto (TPM) indican cuántos tokens puede procesar un usuario específico o una aplicación utilizando un modelo particular en el transcurso de un minuto. Es una forma de medir y limitar el uso, especialmente cuando estás interactuando con el modelo a través de una API.

El TPM es importante porque los modelos de lenguaje, especialmente los grandes, pueden consumir muchos recursos computacionales al procesar texto. Limitar el número de tokens procesados por minuto ayuda a evitar un uso excesivo y garantiza que los recursos estén disponibles para todos los usuarios.

La columna "RPM" en la tabla se refiere a "Requests Per Minute". Es una medida de cuántas solicitudes individuales un usuario o una aplicación puede hacer a un modelo en particular a través de una API en el transcurso de un minuto.

Esto es especialmente relevante para aplicaciones y desarrolladores que utilizan la API de OpenAI (u otras APIs similares) para interactuar con modelos de lenguaje. El límite de RPM está diseñado para controlar el tráfico hacia el modelo y garantizar que el servicio se mantenga estable y disponible para todos los usuarios. Si una aplicación o usuario supera el límite de RPM, es probable que las solicitudes adicionales sean rechazadas hasta que el número de solicitudes se reduzca por debajo del límite permitido.

**NOTA:** El código anterior no funcionó para modelos de chat, por lo que me sugirió cambiar mi código:

> Respuesta de CHATGPT-4 al preguntarle sobre el error arrojado al intentar usar el modelo `gpt-3.5-turbo`

El error que estás viendo indica que estás tratando de usar un modelo de chat (como gpt-3.5-turbo u otros modelos de chat) en el endpoint de "completions" (`v1/completions`) de la API de OpenAI, lo cual no es correcto para esos modelos.

Para solucionar este problema, deberás usar el endpoint `v1/chat/completions` en lugar de `v1/completions`.

Aquí te muestro cómo puedes hacerlo:

1. Asegúrate de tener instalada la biblioteca `openai`.
   
   Si no la tienes, instálala con:
   ```bash
   pip install openai
   ```

2. Cambia tu código para que use el endpoint correcto:

   ```python
   import openai

   # Configura tu API Key
   openai.api_key = 'TU_API_KEY'

   # Utiliza el endpoint correcto
   response = openai.ChatCompletion.create(
     model="gpt-3.5-turbo",
     messages=[
         {"role": "system", "content": "You are a helpful assistant."},
         {"role": "user", "content": "Who won the world series in 2020?"},
     ]
   )

   # Imprime la respuesta
   print(response.choices[0].message['content'])
   ```

En este ejemplo, en lugar de utilizar la función `Completion` (que se usa para el endpoint `v1/completions`), estamos utilizando `ChatCompletion` para hacer peticiones al endpoint `v1/chat/completions`. También notarás que la estructura de entrada es diferente; en lugar de proporcionar un simple `prompt`, suministras una lista de `messages`.

Con estos cambios, deberías poder interactuar con el modelo de chat sin problemas.

> Hacemos las correcciones y solicitamos generar un código para mostrar una imagen con Python en Google Colab

![ChatCompletion en Python](./screenshots/c103/image-1.png)

> Respuesta en extraída

![ChatCompletion extract content](./screenshots/c103/image-2.png)

Claro, aquí tienes un código para generar una imagen y mostrarla en Google Colab utilizando la biblioteca PIL (Python Imaging Library):

```python
from PIL import Image
import matplotlib.pyplot as plt

# Crear una imagen en blanco de 200x200 píxeles
imagen = Image.new("RGB", (200, 200), "white")

# Dibujar un rectángulo rojo en la imagen
for i in range(50, 150):
    for j in range(50, 150):
        imagen.putpixel((i, j), (255, 0, 0))

# Mostrar la imagen en Google Colab
plt.imshow(imagen)
plt.axis('off')
plt.show()
```

Al ejecutar este código, se generará una imagen en blanco con un rectángulo rojo en el centro. Luego, la imagen se mostrará en la salida de la celda de código en Google Colab.

### Flujo de Trabajo con CHATGPT via API

Vamos a establecer un flujo de trabajo para solicitarle a CHATGPT que resuelva tareas extraídas desde un archivo de texto y vaya colocando los resultados generados en documentos de Markdown. Luego solicitaremos a CHATGPT que nos genere el código en Python para leer todos los archivos de Markdown y guardarlos en un PDF.

```py
#
# Por Alan Badillo Salas (alan@nomadacode.com)
# Creado el 11 de Agosto de 2023
#
# CHATGPT MARKDOWN FUNCTION WORKFLOW
#
# Esta función lee un archivo con las instrucciones que debe procesar CHATGPT
# asumiendo un rol de como comportarse y generando un archivo de Markdown
# con los resultados generados.
#
# El archivo debe ser similar al siguiente ejemplo:
#
# APIKEY: YOUR_APIKEY
#
# OUTPUT: mi_respuesta.md
#
# ROLE: 
# ... Eres un programado de Python
#
# INSTRUCTIONS:
# ... Genera un programa en Python que muestre los primeros 10 números primos
# ... Describe el código paso por paso
# 
# * Este código pertenece al curso de Introducción a CHATGPT con Python
#   del Centro de Investigación en Computación 
#   del Instituto Politécnico Nacional
#

def chatgpt_md(file_instructions):
  import re
  with open(file_instructions, "r") as f:
    content = f.read()
    api_key = "YOUR_APIKEY"
    for match in re.finditer(r"APIKEY:\s*([^\n]*)", content):
      if match != None:
        api_key = match.group(1).strip()
    output_file = "output.md"
    for match in re.finditer(r"OUTPUT:\s*([^\n]*)", content):
      if match != None:
        output_file = match.group(1).strip()
    role = "CHATGPT ASSISTANT"
    for match in re.finditer(r"ROLE:\s*\n((...\s*[^\n]*\n)+)", content):
      if match != None:
        role = "\n".join(map(lambda s: s.strip(), match.group(1).split("...")[1:]))
    instructions = "HELLO WORLD"
    for match in re.finditer(r"INSTRUCTIONS:\s*\n((...\s*[^\n]*\n?)+)", content):
      if match != None:
        instructions = "\n".join(map(lambda s: s.strip(), match.group(1).split("...")[1:]))
    print("OUTPUT:", output_file)
    print("ROLE:")
    print(role)
    print("INSTRUCTIONS:")
    print(instructions)

    import openai

    openai.api_key = api_key

    # Utiliza el endpoint correcto
    response = openai.ChatCompletion.create(
      model="gpt-3.5-turbo",
      messages=[
          {"role": "system", "content": role},
          {"role": "user", "content": instructions},
      ]
    )

    i = 0
    for choice in response.choices:
      content = choice.message.content
      if i > 0:
        filename = re.sub(r"\.md", f"{i}.md", output_file)
      else:
        filename = output_file
      with open(output_file, "w") as g:
        g.writelines(content)
      i += 1
    print("OK")

chatgpt_md("/content/generar_numeros_primos.txt")
```

> Contenido de `generar_numeros_primos.txt`

```text
APIKEY: YOUR_APIKEY

OUTPUT: mi_respuesta.md

ROLE: 
... Eres un programado de Python

INSTRUCTIONS:
... Genera un programa en Python que muestre los primeros 10 números primos
... Describe el código paso por paso
```