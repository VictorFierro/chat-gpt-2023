# Clase 106 - SPEECH-TO-TEXT y TEXT-TO-SPEECH

> **Centro de Investigación en Computación**
>
> *Instituto Politécnico Nacional*
>
> Departamento de Diplomados y Extensión Profesional
>

![CIC-IPN](https://www.cic.ipn.mx/images/logos/logositiocicletras.png)

**Profesor**: [Alan Badillo Salas](alan@nomadacode.com)

---

## Contenido

    1. Descargar el audio de un video
    2. Transcribir el audio con OpenAI (**Speech to Text**)
    3. Analizar un texto con OpenAI (**Chat API**)
    4. Convertir un texto a audio con `pyttsx3` (**Text to Speech**)

## Objetivos

Aprender a convertir audio en texto y texto en audio en Python mediante la programación asistida por CHATGPT. Recuperar el texto de un audio y posteriormente analizar el texto con plantillas dirigidas a CHATGPT. Convertir los resultados de texto generados por CHATGPT en audio (locución artificial). Extraer el audio desde un video. Descargar videos de fuentes remotas. Generar videos con imágenes generadas por DALL-E relacionadas al texto.

## Descargar el audio de un video

> Instalar la librería `pytube`

```bash
!pip install pytube
```

> Descargar el video desde la *url*

```py
from pytube import YouTube

url = "https://www.youtube.com/watch?v=SqB4FSettTI"

yt = YouTube(url)

stream = yt.streams.filter(only_audio=True, file_extension="mp4").first()

output_audio = stream.download()

print(output_audio)
```

> Resultado en `Google Colab`

![Download video](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.39.36.png>)

## Transcribir el audio con OpenAI (**Speech to Text**)

> Instalar la librería de OpenAI

```bash
!pip install openai
```

> Transcribir el audio (donde `output_audio` es la ruta al audio)

```py
import openai

openai.api_key = 'TU_API_KEY'

audio_file = open(output_audio, "rb")

transcript = openai.Audio.transcribe("whisper-1", audio_file)

print(transcript.text)
```

> Resultado en `Google Colab`

![Transcript audio](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.40.53.png>)

## Analizar un texto con OpenAI (**Chat API**)

> User Chat API de OpenAI para analizar el audio transcrito

```py
import openai

openai.api_key = 'TU_API_KEY'

response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Eres un asistente que genera síntesis de textos"},
        {"role": "user", "content": f"Resume el siguiente texto:\n\n{transcript.text}"},
    ]
)

texto = response.choices[0].message['content']

print(texto)
```

> Resultado en `Google Colab`

![Analyze text](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.42.10.png>)

## Convertir un texto a audio con `pyttsx3` (**Text to Speech**)

> Instalar `pyttsx3`

```bash
!pip install pyttsx3
```

> Instalar `espeak`

```bash
!sudo apt install espeak
```

> Resultado de la instalación en `Google Colab`

![Install pyttsx3](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.43.23.png>)

> Mostrar la lista de voces disponibles

```py
import pyttsx3

engine = pyttsx3.init()

voices = engine.getProperty('voices')

for voice in voices:
    print("Voz:", voice.id)
    print(" - Nombre:", voice.name)
    print(" - Idioma:", voice.languages)
    print(" - Género:", voice.gender)
    print("")
```

> Resultado de la lista de voces en `Google Colab`

![Voices pyttsx3](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.44.17.png>)

> Procesar el texto como audio y guardarlo como el archivo `audio.mp3`

```py
import pyttsx3

engine = pyttsx3.init()

engine.setProperty('voice', 'spanish')

engine.save_to_file(texto, "audio.mp3")

engine.runAndWait()
```

> Resultado de la creación del audio en `Google Colab`

![Audio pyttsx3](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.45.14.png>)

> Código de la narración en `Mac OSX`

![Mac OSX pyttsx3 code](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.46.48.png>)

> Resultado de la narración en `Mac OSX`

![Mac OSX pyttsx3 terminal](<./screenshots/p106/Captura de pantalla 2023-09-01 a la(s) 22.47.40.png>)
